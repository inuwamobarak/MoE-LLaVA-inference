# MoE-LLaVA-inference
The ever-evolving landscape of artificial intelligence has presented an intersection of visual and linguistic data through large vision-language models (LVLMs).  MoE-LLaVA is one of these models which stands at the forefront of revolutionizing how machines interpret and understand the world, mirroring human-like perception. However, the challenge still lies in finding the balance between model performance and the computation for their deployment.


![cover](https://github.com/inuwamobarak/MoE-LLaVA-inference/assets/65142149/94569fb5-f905-4ec6-97df-b69ffaa838df)
